{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U-nets, vortex detection, and semantic segmentation\n",
    "\n",
    "In this file, we will train a semantic image segmentation network to identify regions of high vorticity and velocity in our simulation, given only a screenshot of the fluid density. One appropriate choice of network architecture for this scenario is the U-net, named for its characteristic shape:\n",
    "\n",
    "![](images/unet-arch.png)\n",
    "\n",
    "The intuition behind the U-net is that convolutional implementations coarse-grain data in the input image in order to extract low-level feature data. Coarse-graining is a non-invertible process and thus destroys information about correlations, so we feed the data at each layer forward, to build up an image which has the same size and resolution as the input and has access to the correlations at each CONV block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras import layers\n",
    "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D, UpSampling2D\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "import pydot\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "from resnets_utils import *\n",
    "from keras.initializers import glorot_uniform\n",
    "import scipy.misc\n",
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline\n",
    "\n",
    "import keras.backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "K.set_learning_phase(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UNet(input_shape = (128, 128, 3)):\n",
    "    \"\"\"\n",
    "    Implementation of the popular ResNet50 the following architecture:\n",
    "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
    "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
    "\n",
    "    Arguments:\n",
    "    input_shape -- shape of the images of the dataset\n",
    "    classes -- integer, number of classes\n",
    "\n",
    "    Returns:\n",
    "    model -- a Model() instance in Keras\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the input as a tensor with shape input_shape\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    \n",
    "    # Zero-Padding\n",
    "    #X = ZeroPadding2D((3, 3))(X_input)\n",
    "    #X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n",
    "    # AVGPOOL (â‰ˆ1 line). Use \"X = AveragePooling2D(...)(X)\"\n",
    "    #X = AveragePooling2D(pool_size=(2,2), name='avg_pool')(X)\n",
    "    #X = Flatten()(X)\n",
    "    #X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    \n",
    "    # Stage 1d\n",
    "    X = Conv2D(64, (3, 3), strides = (1, 1), name = 'convd1a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn_convd1a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = Conv2D(64, (3, 3), strides = (1, 1), name = 'convd1b', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn_convd1b')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X_shortcut_1 = X\n",
    "    \n",
    "    # Downward step 1\n",
    "    X = MaxPooling2D((2, 2), strides=(2, 2))(X)\n",
    "\n",
    "    # Stage 2d\n",
    "    X = Conv2D(128, (3, 3), strides = (1, 1), name = 'convd2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn_convd2a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = Conv2D(128, (3, 3), strides = (1, 1), name = 'convd2b', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn_convd2b')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X_shortcut_2 = X\n",
    "    \n",
    "    # Downward step 2d\n",
    "    X = MaxPooling2D((2, 2), strides=(2, 2))(X)\n",
    "\n",
    "    # Stage 3d \n",
    "    X = Conv2D(256, (3, 3), strides = (1, 1), name = 'convd3a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn_convd3a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = Conv2D(256, (3, 3), strides = (1, 1), name = 'convd3b', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn_convd3b')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X_shortcut_3 = X\n",
    "\n",
    "    # Downward step 3\n",
    "    X = MaxPooling2D((2, 2), strides=(2, 2))(X)\n",
    "    \n",
    "    # Stage 4d\n",
    "    X = Conv2D(512, (3, 3), strides = (1, 1), name = 'convd4a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn_convd4a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = Conv2D(512, (3, 3), strides = (1, 1), name = 'convd4b', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn_convd4b')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X_shortcut_4 = X\n",
    "\n",
    "    # Downward step 4\n",
    "    X = MaxPooling2D((2, 2), strides=(2, 2))(X)\n",
    "    \n",
    "    # Stage 5b\n",
    "    X = Conv2D(1024, (3, 3), strides = (1, 1), name = 'convb5a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn_convb5a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = Conv2D(1024, (3, 3), strides = (1, 1), name = 'convb5b', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn_convb5b')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    # Upward step 4\n",
    "    X = UpSampling2D(size=(2, 2), interpolation='nearest')(X)\n",
    "    X = Add()([X_shortcut_4,X])\n",
    "    \n",
    "    # Stage 4u\n",
    "    X = Conv2D(512, (3, 3), strides = (1, 1), name = 'convu4a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn_convu4a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = Conv2D(512, (3, 3), strides = (1, 1), name = 'convu4b', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn_convu4b')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    # Upward step 3\n",
    "    X = UpSampling2D(size=(2, 2), interpolation='nearest')(X)\n",
    "    X = Add()([X_shortcut_3,X])\n",
    "    \n",
    "    # Stage 3u\n",
    "    X = Conv2D(256, (3, 3), strides = (1, 1), name = 'convu3a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn_convu3a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = Conv2D(256, (3, 3), strides = (1, 1), name = 'convu3b', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn_convu3b')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    # Upward step 2\n",
    "    X = UpSampling2D(size=(2, 2), interpolation='nearest')(X)\n",
    "    X = Add()([X_shortcut_2,X])\n",
    "    \n",
    "    # Stage 2u\n",
    "    X = Conv2D(128, (3, 3), strides = (1, 1), name = 'convu2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn_convu2a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = Conv2D(128, (3, 3), strides = (1, 1), name = 'convu2b', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn_convu2b')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    # Upward step 1\n",
    "    X = UpSampling2D(size=(2, 2), interpolation='nearest')(X)\n",
    "    X = Add()([X_shortcut_1,X])\n",
    "    \n",
    "    # Stage 1u\n",
    "    X = Conv2D(64, (3, 3), strides = (1, 1), name = 'convu1a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn_convu1a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = Conv2D(64, (3, 3), strides = (1, 1), name = 'convu1b', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn_convu1b')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    # output layer\n",
    "    X = Conv2D(1, (1, 1), strides = (1, 1), name = 'convOut', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn_convOut')(X)\n",
    "    X = Activation('sigmoid')(X)\n",
    "    \n",
    "    \n",
    "    # Create model\n",
    "    model = Model(inputs = X_input, outputs = X, name='UNet')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ResNet50' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-383ade38d424>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mResNet50\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'ResNet50' is not defined"
     ]
    }
   ],
   "source": [
    "model = UNet(input_shape = (128, 128, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_orig, Y_train_orig, X_test_orig, Y_test_orig, classes = load_dataset()\n",
    "\n",
    "# Normalize image vectors\n",
    "X_train = X_train_orig/255.\n",
    "X_test = X_test_orig/255.\n",
    "\n",
    "# Convert training and test labels to one hot matrices\n",
    "Y_train = convert_to_one_hot(Y_train_orig, 6).T\n",
    "Y_test = convert_to_one_hot(Y_test_orig, 6).T\n",
    "\n",
    "print (\"number of training examples = \" + str(X_train.shape[0]))\n",
    "print (\"number of test examples = \" + str(X_test.shape[0]))\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(Y_train.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))\n",
    "print (\"Y_test shape: \" + str(Y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, Y_train, epochs = 2, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.evaluate(X_test, Y_test)\n",
    "print (\"Loss = \" + str(preds[0]))\n",
    "print (\"Test Accuracy = \" + str(preds[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = 'images/my_image.jpg'\n",
    "img = image.load_img(img_path, target_size=(64, 64))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = x/255.0\n",
    "print('Input image shape:', x.shape)\n",
    "my_image = scipy.misc.imread(img_path)\n",
    "imshow(my_image)\n",
    "print(\"class prediction vector [p(0), p(1), p(2), p(3), p(4), p(5)] = \")\n",
    "print(model.predict(x))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
